{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 18:57:14.653027: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 895ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 454ms/step\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 471ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/satyaki/Desktop/Python-HP/webcam.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/satyaki/Desktop/Python-HP/webcam.ipynb#ch0000000?line=55'>56</a>\u001b[0m np\u001b[39m.\u001b[39munique(mapping)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/satyaki/Desktop/Python-HP/webcam.ipynb#ch0000000?line=56'>57</a>\u001b[0m blurred_original_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mGaussianBlur(frame,(\u001b[39m19\u001b[39m,\u001b[39m19\u001b[39m),\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/satyaki/Desktop/Python-HP/webcam.ipynb#ch0000000?line=57'>58</a>\u001b[0m layered_image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(mapping \u001b[39m!=\u001b[39;49m (\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/satyaki/Desktop/Python-HP/webcam.ipynb#ch0000000?line=58'>59</a>\u001b[0m                      frame, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/satyaki/Desktop/Python-HP/webcam.ipynb#ch0000000?line=59'>60</a>\u001b[0m                      blurred_original_image)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/satyaki/Desktop/Python-HP/webcam.ipynb#ch0000000?line=60'>61</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mVideo Segmentation\u001b[39m\u001b[39m\"\u001b[39m, layered_image)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/satyaki/Desktop/Python-HP/webcam.ipynb#ch0000000?line=62'>63</a>\u001b[0m c \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "H = 512\n",
    "W = 512\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = (y_true * y_pred).sum()\n",
    "        union = y_true.sum() + y_pred.sum() - intersection\n",
    "        x = (intersection + 1e-15) / (union + 1e-15)\n",
    "        x = x.astype(np.float32)\n",
    "        return x\n",
    "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
    "\n",
    "smooth = 1e-15\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n",
    "\n",
    "with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss}):\n",
    "  model = tf.keras.models.load_model(\"model_1.h5\")\n",
    "\n",
    "#define a video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "    h, w, _ = frame.shape\n",
    "    x = cv2.resize(frame, (W, H))\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    y = model.predict(x)[0]\n",
    "    y = cv2.resize(y, (w, h))\n",
    "    y = np.expand_dims(y, axis=-1)\n",
    "    y = y > 0.5\n",
    "\n",
    "    photo_mask = frame*y\n",
    "    gray = cv2.cvtColor(photo_mask, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray,(301,301),0)\n",
    "    ret3,thresholded_img = cv2.threshold(blurred,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    mapping = cv2.cvtColor(thresholded_img, cv2.COLOR_GRAY2RGB)\n",
    "    np.unique(mapping)\n",
    "    blurred_original_image = cv2.GaussianBlur(frame,(19,19),0)\n",
    "    layered_image = np.where(mapping != (0,0,0), \n",
    "                         frame, \n",
    "                         blurred_original_image)\n",
    "    cv2.imshow(\"Video Segmentation\", layered_image)\n",
    "\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e841410de0b66c2b175840074dc24237317ce198a3301ef62070dfe400a4d78"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
